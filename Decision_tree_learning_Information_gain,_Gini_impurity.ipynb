{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision tree learning: Information gain, Gini impurity.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csadrian/adatbanya/blob/master/Decision_tree_learning_Information_gain%2C_Gini_impurity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "yKaeU6-o74qJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Döntési fák építése, tisztasági mértékek"
      ]
    },
    {
      "metadata": {
        "id": "KHITVquw6TFg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. Feladat: Tekintsük a klasszikus weather toy adatszetet! A célváltozó, amit meg akarunk jósolni, legyen a play attribútum. Döntési fát akarunk építeni az information gain tisztasági mértéket használva. Számoljuk ki, hogy mely attribútumra kell rákérdeznünk a döntési fa gyökerében!\n"
      ]
    },
    {
      "metadata": {
        "id": "3VXGLdrbzodz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "outlook | temperature | humidity | windy | play\n",
        "---  | --- | --- | --- | --- \n",
        "sunny | hot | high | FALSE | no\n",
        "sunny | hot | high | TRUE | no\n",
        "overcast | hot | high | FALSE | yes\n",
        "rainy | mild | high | FALSE | yes\n",
        "rainy | cool | normal | FALSE | yes\n",
        "rainy | cool | normal | TRUE | no\n",
        "overcast | cool | normal | TRUE | yes\n",
        "sunny | mild | high | FALSE | no\n",
        "sunny | cool | normal | FALSE | yes\n",
        "rainy | mild | normal | FALSE | yes\n",
        "sunny | mild | normal | TRUE | yes\n",
        "overcast | mild | high | TRUE | yes\n",
        "overcast | hot | normal | FALSE | yes\n",
        "rainy | mild | high | TRUE | no"
      ]
    },
    {
      "metadata": {
        "id": "MNJlwwKG0X_5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## A döntési fa gyökere: az első elágazás\n",
        "Nézzük végig minden lehetséges attribútumot, hogy mely mentén elágazva csökken leginkább az entrópia a célváltozóra vonatkozóan!\n",
        "\n",
        "### Ha az outlook attribútumra kérdezünk rá?\n",
        "\n",
        "Outlook = sunny -> yes, yes, no, no, no (2 db yes, 3 db no)\n",
        "$$ E(outlook=sunny) = -\\frac{2}{5} \\cdot \\log \\frac{2}{5} - \\frac{3}{5} \\cdot \\log \\frac{3}{5} = 0.971$$\n",
        "\n",
        "Outlook = overcast -> yes, yes, yes, yes (4 db yes, 0 db no)\n",
        "$$ E(outlook=overcast) = -\\frac{4}{4} \\cdot \\log \\frac{4}{4} - \\frac{0}{4} \\cdot \\log \\frac{0}{4} = 0.0$$\n",
        "\n",
        "Outlook = rainy -> yes, yes, no, yes, no (3 db yes, 2 db no)\n",
        "$$ E(outlook=rainy) = -\\frac{3}{5} \\cdot \\log \\frac{3}{5} - \\frac{2}{5} \\cdot \\log \\frac{2}{5} = 0.971$$\n",
        "\n",
        "$$ I(outlook) = \\frac{5}{14} \\cdot 0.971 + \\frac{4}{14} \\cdot 0.0 + \\frac{5}{14} \\cdot 0.971 = 0.693 $$\n",
        "\n",
        "$$ Gain(outlook) = E(S) - I(outlook) = 0.94 - 0.693 = 0.247  $$\n",
        "\n",
        "Ha az outlook attribútumra kérdezünk rá, ennyivel lesz kevesebb az etrópia a célváltozót tekintve.\n",
        "\n",
        "\n",
        "\n",
        "### Ha a windy attribútumra kérdezünk rá?\n",
        "\n",
        "Windy = TRUE -> no, no, yes, yes, yes, no (3 db yes, 3 db no)\n",
        "$$ E(windy=true) = -\\frac{3}{6} \\cdot \\log \\frac{3}{6} - \\frac{3}{6} \\cdot \\log \\frac{3}{6} = 1.0 $$\n",
        "\n",
        "Windy = FALSE -> no, yes, yes, yes, no, yes, yes, yes (6 db yes, 2 db no)\n",
        "$$ E(windy=false) = -\\frac{6}{8} \\cdot \\log \\frac{6}{8} - \\frac{2}{8} \\cdot \\log \\frac{2}{8} = 0.811 $$\n",
        "\n",
        "$$ I(windy) = \\frac{6}{14} \\cdot 1.0 + \\frac{8}{14} \\cdot 0.811 = 0.892 $$\n",
        "\n",
        "$$ Gain(windy) = E(S) - I(windy) = 0.94 - 0.892 = 0.048  $$\n",
        "\n",
        "\n",
        "Ha a windy attribútumra kérdezünk rá, ennyivel lesz kevesebb az etrópia a célváltozót tekintetve.\n",
        "\n",
        "\n",
        "### Ha a temperature attribútumra kérdezünk rá?\n",
        "\n",
        "$$ Gain(temperature) = 0.029 $$\n",
        "\n",
        "\n",
        "### Ha a humdity attribútumra kérdezünk rá?\n",
        "\n",
        "$$ Gain(humidity) = 0.152 $$\n",
        "\n",
        "### Összefoglalva\n",
        "\n",
        "$$ Gain(windy) = 0.048  $$\n",
        "$$ Gain(temperature) = 0.029 $$\n",
        "$$ Gain(humidity) = 0.152 $$\n",
        "$$ Gain(outlook) = 0.247  $$\n",
        "\n",
        "A legnagyobb information gain értéket az Outlook attribútum esetén kaptuk, így válasszuk ezt az első  elágazáshoz.\n"
      ]
    },
    {
      "metadata": {
        "id": "m-HZ4BVx7bPX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2. Feladat: Rajzoljuk fel, hogy néz ki az első elágazás után a fa!"
      ]
    },
    {
      "metadata": {
        "id": "pQDN6cb08QtL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "3. Feladat: Gondolkodjunk el, hogy hogyan járnánk el akkor, ha folytonos értékű attribútum lenne a temperature változó!"
      ]
    },
    {
      "metadata": {
        "id": "1BmelXRu8zxc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "4. Feladat: Építsük fel a döntési fát egy másik tisztasági mértéket, a Gini tisztasági mértéket használva!"
      ]
    }
  ]
}